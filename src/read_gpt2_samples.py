# -*- coding: utf-8 -*-
"""read_gpt2_samples.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12E8x7-HOwRcxDffmAccUKTMRMoRKIe1k
"""

# !pip install transformers

# from google.colab import drive
# drive.mount('/content/drive')

# path = "/content/drive/My Drive/CS224N/final_phase2/"

import pickle
from transformers import GPT2Tokenizer
import torch

tokenizer = GPT2Tokenizer.from_pretrained('gpt2-medium', bos_token='<|startoftext|>',
                                          eos_token='<|endoftext|>', pad_token='<|pad|>')

types = [
    "ENFP",
    "ENFJ",
    "ESTJ",
    "ESFJ",
    "ESTP",
    "ESFP",
    "ENTJ",
    "ENTP",
    "INFP",
    "INTP",
    "INFJ",
    "INTJ",
    "ISFP",
    "ISTP",
    "ISFJ",
    "ISTJ"
]

all_texts = {}

for t in types[:7]:
    with open(f'../stats/{t}_samples.pickle', 'rb') as f:
        samples = pickle.load(f)
        texts = tokenizer.batch_decode(samples)
        for i in range(len(texts)):
            texts[i] = texts[i].replace("<|startoftext|>", '')
            texts[i] = texts[i].replace("<|endoftext|>", '')
        all_texts[f"{t}"] = texts
        print(texts)
    print("====================================")

texts

import pandas as pd
data = pd.read_csv("../stats/generated_data.csv")

data["post"][1]

